{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from algos.classical import *\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio    \n",
    "import glob\n",
    "from sklearn.model_selection import KFold\n",
    "from statistics import mean, stdev, variance\n",
    "from ReliefF import ReliefF\n",
    "import time\n",
    "import scipy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import cluster\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_Table = pd.read_csv('./Filter/Accuracy.csv', index_col=0)\n",
    "Features_Table = pd.read_csv('./Filter/Features.csv', index_col=0)\n",
    "Time_Table = pd.read_csv('./Filter/Time.csv', index_col=0)\n",
    "Fitness_Table = pd.read_csv('./Filter/Fitness.csv', index_col=0)\n",
    "Curve_Table = pd.read_csv('./Filter/Convergence.csv', index_col=0)\n",
    "Tables = [Accuracy_Table, Features_Table, Time_Table, Fitness_Table]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pearson(X, y, nfeat, sel_features = []):\n",
    "    \n",
    "    variables = []\n",
    "    for col in range(X.shape[1]):\n",
    "        ans = pearsonr(X[:, col], y.reshape(-1))\n",
    "        variables.append({'col' : col, 'var' : abs(ans[0])})\n",
    "\n",
    "    sortedvars = sorted(variables, key=lambda d: d['var'], reverse= True) \n",
    "\n",
    "    self_pearson = []\n",
    "\n",
    "    X_new = np.empty((X.shape[0], 0))\n",
    "    for i in range(min(X.shape[1], nfeat)):\n",
    "        self_pearson.append(sortedvars[i]['col'])\n",
    "        X_new = np.concatenate((X_new, X[:, sortedvars[i]['col']].reshape(-1, 1)), 1)\n",
    "\n",
    "    Xp = X_new\n",
    "    sel_features.append(self_pearson)\n",
    "    return Xp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Relief(X, y, nfeat, sel_features = []):\n",
    "\n",
    "    n = np.size(X, 0)\n",
    "    y_temp = y.reshape(n)        \n",
    "    fs = ReliefF(n_neighbors=10, n_features_to_keep = nfeat)\n",
    "    Xr = fs.fit_transform(X, y_temp)\n",
    "    sel_features.append(fs.top_features[:nfeat])\n",
    "    return Xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fval(X, y, nfeat, sel_features = []):\n",
    "\n",
    "    mf = SelectKBest(f_classif, k=nfeat)\n",
    "    Xf = mf.fit_transform(X, y.reshape(-1))\n",
    "\n",
    "    variables = []\n",
    "    for col in range(X.shape[1]):\n",
    "        variables.append({'col' : col, 'var' : mf.scores_[col]})\n",
    "\n",
    "    sortedvars = sorted(variables, key=lambda d: d['var'], reverse= True) \n",
    "\n",
    "    self_fclass = []\n",
    "\n",
    "    for i in range(min(X.shape[1], nfeat)):\n",
    "        self_fclass.append(sortedvars[i]['col'])\n",
    "    sel_features.append(self_fclass)\n",
    "    return Xf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MutualInfo(X, y, nfeat, sel_features = []):\n",
    "\n",
    "    mf = SelectKBest(mutual_info_classif, k=nfeat)\n",
    "    Xm = mf.fit_transform(X, y.reshape(-1))\n",
    "\n",
    "    variables = []\n",
    "    for col in range(X.shape[1]):\n",
    "        variables.append({'col' : col, 'var' : mf.scores_[col]})\n",
    "\n",
    "    sortedvars = sorted(variables, key=lambda d: d['var'], reverse= True) \n",
    "\n",
    "    self_mclass = []\n",
    "\n",
    "    for i in range(min(X.shape[1], 100)):\n",
    "        self_mclass.append(sortedvars[i]['col'])\n",
    "    sel_features.append(self_mclass)\n",
    "    return Xm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Union1(X, y, nfeat):\n",
    "    BaseMethods = [Pearson, Relief, Fval, MutualInfo]\n",
    "    sel_features = []\n",
    "    \n",
    "    for method in BaseMethods:\n",
    "        Xtemp = method(X, nfeat, sel_features)\n",
    "    \n",
    "    sel_features = np.asarray(sel_features)\n",
    "    sel_features = [i[:50] for i in sel_features]\n",
    "    union_array = np.asarray([])\n",
    "    \n",
    "    for i in range(len(sel_features)):\n",
    "        union_array = np.union1d(union_array, sel_features[i])\n",
    "    \n",
    "    X_new = np.empty((X.shape[0], 0))\n",
    "    for i in range(len(union_array)):\n",
    "        X_new = np.concatenate((X_new, X[:, int(union_array[i])].reshape(-1, 1)), 1)\n",
    "    \n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Union2(X, y, nfeat):\n",
    "    BaseMethods = [Pearson, Relief, Fval, MutualInfo]\n",
    "    sel_features = []\n",
    "    \n",
    "    for method in BaseMethods:\n",
    "        Xtemp = method(X, nfeat, sel_features)\n",
    "    \n",
    "    sel_features = np.asarray(sel_features)\n",
    "    union_array = np.asarray([])\n",
    "    \n",
    "    for i in range(sel_features.shape[1]):\n",
    "        for j in range(sel_features.shape[0]):\n",
    "            union_array = np.union1d(union_array, np.asarray([sel_features[j][i]]))\n",
    "        if len(union_array) >= 100:\n",
    "            break\n",
    "    \n",
    "    X_new = np.empty((X.shape[0], 0))\n",
    "    for i in range(len(union_array)):\n",
    "        X_new = np.concatenate((X_new, X[:, int(union_array[i])].reshape(-1, 1)), 1)\n",
    "    \n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    x = np.asarray(x)\n",
    "    return (x - x.min()) / (np.ptp(x))\n",
    "\n",
    "\n",
    "def UnionRankNorm(X, y, nfeat):\n",
    "    \n",
    "    pearson_score = []\n",
    "    for col in range(X.shape[1]):\n",
    "        ans = pearsonr(X[:, col], y.reshape(-1))\n",
    "        pearson_score.append(abs(ans[0]))\n",
    "    \n",
    "    pearson_score = np.asarray(pearson_score)\n",
    "    mms = MinMaxScaler()\n",
    "    ps_norm = normalize(pearson_score)\n",
    "    \n",
    "    n = np.size(X, 0)\n",
    "    y_temp = y.reshape(n)        \n",
    "    fs = ReliefF(n_neighbors=10, n_features_to_keep = nfeat)\n",
    "    Xr = fs.fit_transform(X, y_temp)\n",
    "    relief_score = fs.feature_scores\n",
    "    rs_norm = normalize(relief_score)\n",
    "    \n",
    "    mf = SelectKBest(f_classif, k=nfeat)\n",
    "    Xf = mf.fit_transform(X, y.reshape(-1))\n",
    "    f_score = mf.scores_\n",
    "    fs_norm = normalize(f_score)\n",
    "    \n",
    "    mf = SelectKBest(mutual_info_classif, k=nfeat)\n",
    "    Xm = mf.fit_transform(X, y.reshape(-1))\n",
    "    mi_score = mf.scores_\n",
    "    mi_norm  = normalize(mi_score)\n",
    "    \n",
    "    \n",
    "    variables = []\n",
    "    for col in range(X.shape[1]):\n",
    "        avg_score = (ps_norm[col] + rs_norm[col] + fs_norm[col] + mi_norm[col])/4\n",
    "        variables.append({'col' : col, 'var' : avg_score})\n",
    "\n",
    "    sortedvars = sorted(variables, key=lambda d: d['var'], reverse= True) \n",
    "    \n",
    "    X_new = np.empty((X.shape[0], 0))\n",
    "    for i in range(min(X.shape[1], nfeat)):\n",
    "        X_new = np.concatenate((X_new, X[:, sortedvars[i]['col']].reshape(-1, 1)), 1)\n",
    "\n",
    "    return X_new\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UnionCluster(X, y, nfeat):\n",
    "    \n",
    "    pearson_score = []\n",
    "    for col in range(X.shape[1]):\n",
    "        ans = pearsonr(X[:, col], y.reshape(-1))\n",
    "        pearson_score.append(abs(ans[0]))\n",
    "    \n",
    "    pearson_score = np.asarray(pearson_score)\n",
    "    ps_std = (pearson_score - pearson_score.mean())/(pearson_score.std())\n",
    "    \n",
    "    n = np.size(X, 0)\n",
    "    y_temp = y.reshape(n)        \n",
    "    fs = ReliefF(n_neighbors=10, n_features_to_keep = nfeat)\n",
    "    Xr = fs.fit_transform(X, y_temp)\n",
    "    relief_score = fs.feature_scores\n",
    "    rs_std = (relief_score - relief_score.mean())/(relief_score.std())\n",
    "    \n",
    "    mf = SelectKBest(f_classif, k=nfeat)\n",
    "    Xf = mf.fit_transform(X, y.reshape(-1))\n",
    "    f_score = mf.scores_\n",
    "    fs_std = (f_score - f_score.mean())/(f_score.std())\n",
    "    \n",
    "    mf = SelectKBest(mutual_info_classif, k=nfeat)\n",
    "    Xm = mf.fit_transform(X, y.reshape(-1))\n",
    "    mi_score = mf.scores_\n",
    "    ms_std = (mi_score - mi_score.mean())/(mi_score.std())\n",
    "    \n",
    "    matrix = np.asarray([ps_std, rs_std, fs_std, ms_std]).transpose()\n",
    "    \n",
    "    kmeans = KMeans(n_clusters = 3).fit(matrix)\n",
    "    centres = kmeans.cluster_centers_\n",
    "    scores = []\n",
    "    for centre in centres:\n",
    "        mean_score = np.mean(centre)\n",
    "        scores.append(mean_score)\n",
    "    \n",
    "    max_score_index = 0\n",
    "    for i in range(len(scores)):\n",
    "        if scores[i] > scores[max_score_index]:\n",
    "            max_score_index = i\n",
    "    \n",
    "    X_new = np.empty((X.shape[0], 0))\n",
    "    \n",
    "    labels = kmeans.labels_\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] == max_score_index:\n",
    "            X_new = np.concatenate((X_new, X[:, i].reshape(-1, 1)), 1)\n",
    "\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11_TUMORS\n",
      "Low Variance Features removed\n",
      "Standardized\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 174 and the array at index 1 has size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-159-403a735a9058>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Standardized'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{Filter_name} Filter approach applied'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-158-3da114770cf3>\u001b[0m in \u001b[0;36mUnionCluster\u001b[1;34m(X, y, nfeat)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mmax_score_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m             \u001b[0mX_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX_new\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 174 and the array at index 1 has size 4"
     ]
    }
   ],
   "source": [
    "FilterMethods = [UnionCluster]\n",
    "\n",
    "for method in FilterMethods:\n",
    "    Filter_name = method.__name__.upper()\n",
    "    \n",
    "    for i in range(len(Tables)):\n",
    "        if not Filter_name in Tables[i].columns:\n",
    "            Tables[i][Filter_name] = \"\"\n",
    "    \n",
    "    if not Filter_name in Curve_Table.columns:\n",
    "            Curve_Table[Filter_name] = \"\"\n",
    "    \n",
    "    files = glob.glob(\"datasets/*.mat\")\n",
    "    files = list(files)\n",
    "    files.sort()\n",
    "    \n",
    "    for file in files:\n",
    "        \n",
    "        dataset_name = file[9:-4].upper()\n",
    "        print(dataset_name)\n",
    "        data  = sio.loadmat(file)\n",
    "        X  = data['X']\n",
    "        if type(X) is scipy.sparse.csc.csc_matrix:\n",
    "            X = X.toarray()\n",
    "        else:\n",
    "            X = np.asarray(X)\n",
    "        y = np.asarray(data['Y'])\n",
    "        \n",
    "        variables = []\n",
    "        for col in range(X.shape[1]):\n",
    "            variables.append({'col' : col, 'var' : np.var(X[:, col])})\n",
    "        \n",
    "        sortedvars = sorted(variables, key=lambda d: d['var'], reverse= True) \n",
    "        \n",
    "        X_new = np.empty((X.shape[0], 0))\n",
    "        for i in range(min(X.shape[1], 5000)):\n",
    "            X_new = np.concatenate((X_new, X[:, sortedvars[i]['col']].reshape(-1, 1)), 1)\n",
    "        \n",
    "        X = X_new\n",
    "        X_new = None\n",
    "        variables = None\n",
    "        sortedvars = None\n",
    "        \n",
    "        print('Low Variance Features removed')\n",
    "        X = StandardScaler().fit_transform(X)\n",
    "        print('Standardized')\n",
    "        \n",
    "        X = method(X, y, 100)\n",
    "        print(f'{Filter_name} Filter approach applied')\n",
    "        \n",
    "        runs = 10\n",
    "        Accuracy_Score = []\n",
    "        Fitness_Score = []\n",
    "        Selected_Features = []\n",
    "        Convergence_curve = []\n",
    "        Time = []\n",
    "        Scores = [Accuracy_Score, Selected_Features, Time, Fitness_Score]\n",
    "    \n",
    "        k    = 5     # k-value in KNN\n",
    "        N    = 20    # number of particles\n",
    "        T    = 100   # maximum number of iterations\n",
    "\n",
    "        opts = {'k':k, 'N':N, 'T':T}\n",
    "\n",
    "        for i in range(runs):\n",
    "            start_time = time.time()\n",
    "            fmdl = pso(X, y, opts)\n",
    "            time_taken = time.time() - start_time\n",
    "            \n",
    "            Acc       = fmdl['acc']\n",
    "            num_feat = float(fmdl['num_feat'])\n",
    "            curve   = fmdl['c']\n",
    "            curve   = curve.reshape(np.size(curve,1))\n",
    "            fitness = fmdl['fitness']\n",
    "\n",
    "            print(f' Run {i+1}')\n",
    "            print(\"Accuracy:\", 100 * Acc)\n",
    "            print(\"Feature Size:\", num_feat)\n",
    "            print(\"Fitness:\", fitness)\n",
    "            print(\"Time:\", time_taken)\n",
    "            print('------------------------------------')\n",
    "\n",
    "            Accuracy_Score.append(Acc)\n",
    "            Fitness_Score.append(fitness)\n",
    "            Selected_Features.append(num_feat)\n",
    "            Convergence_curve = curve\n",
    "            Time.append(time_taken)\n",
    "\n",
    "        print(f'Filter Approach : {Filter_name} Dataset : {dataset_name}')\n",
    "        print(\"Accuracy:\", 100*mean(Accuracy_Score))\n",
    "        print(\"Feature Size:\", mean(Selected_Features))\n",
    "        print(\"Fitness:\", mean(Fitness_Score))\n",
    "        print(\"Time:\", mean(Time))\n",
    "\n",
    "        x = np.arange(0, opts['T'], 1.0) + 1.0\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(x, Convergence_curve, 'o-')\n",
    "        ax.set_xlabel('Number of Iterations')\n",
    "        ax.set_ylabel('Fitness')\n",
    "        ax.set_title(f'{Filter_name}')\n",
    "        ax.grid()\n",
    "        plt.show()\n",
    "        \n",
    "        if not (Accuracy_Table['Dataset'] == dataset_name).any():\n",
    "            arr1 = [dataset_name, 'All']\n",
    "            arr2 = [dataset_name, 'Avg']\n",
    "            arr3 = [dataset_name, 'Std']\n",
    "            arr4 = [dataset_name]\n",
    "            \n",
    "            for i in range(len(Tables)):\n",
    "                df1 = pd.DataFrame([arr1 + [np.nan]*(len(Tables[i].columns)-2)], columns=Tables[i].columns)\n",
    "                df2 = pd.DataFrame([arr2 + [np.nan]*(len(Tables[i].columns)-2)], columns=Tables[i].columns)\n",
    "                df3 = pd.DataFrame([arr3 + [np.nan]*(len(Tables[i].columns)-2)], columns=Tables[i].columns)\n",
    "                Tables[i] = Tables[i].append(df1, ignore_index=True)\n",
    "                Tables[i] = Tables[i].append(df2, ignore_index=True)\n",
    "                Tables[i] = Tables[i].append(df3, ignore_index=True)\n",
    "            \n",
    "            df4 = pd.DataFrame([arr4 + [np.nan]*(len(Curve_Table.columns)-1)], columns=Curve_Table.columns)\n",
    "            Curve_Table = Curve_Table.append(df4, ignore_index=True)\n",
    "        \n",
    "        for i in range(len(Tables)):\n",
    "            index = Tables[i].index\n",
    "            condition = (Tables[i]['Dataset'] == dataset_name) & (Tables[i]['Metric'] == 'All')\n",
    "            index = index[condition].tolist()[0]\n",
    "            Tables[i].at[index, Filter_name] = Scores[i]\n",
    "            \n",
    "            index = Tables[i].index\n",
    "            condition = (Tables[i]['Dataset'] == dataset_name) & (Tables[i]['Metric'] == 'Avg')\n",
    "            index = index[condition].tolist()[0]\n",
    "            Tables[i].at[index, Filter_name] = mean(Scores[i])\n",
    "            \n",
    "            index = Tables[i].index\n",
    "            condition = (Tables[i]['Dataset'] == dataset_name) & (Tables[i]['Metric'] == 'Std')\n",
    "            index = index[condition].tolist()[0]\n",
    "            Tables[i].at[index, Filter_name] = stdev(Scores[i])\n",
    "        \n",
    "        index = Curve_Table.index\n",
    "        condition = (Curve_Table['Dataset'] == dataset_name)\n",
    "        index = index[condition].tolist()[0]\n",
    "        Curve_Table[Filter_name] = Curve_Table[Filter_name].astype(object)\n",
    "        Curve_Table.at[index, Filter_name] = Convergence_curve\n",
    "        \n",
    "        file_name = './Filter/Convergence.csv'\n",
    "        Curve_Table.to_csv(file_name)\n",
    "        file_name = './Filter/Accuracy.csv'\n",
    "        Tables[0].to_csv(file_name)\n",
    "        file_name = './Filter/Features.csv'\n",
    "        Tables[1].to_csv(file_name)\n",
    "        file_name = './Filter/Time.csv'\n",
    "        Tables[2].to_csv(file_name)\n",
    "        file_name = './Filter/Fitness.csv'\n",
    "        Tables[3].to_csv(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>PEARSON</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Metric, PEARSON]\n",
       "Index: []"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_Table = pd.DataFrame(columns=['Dataset', 'Metric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_Table = pd.DataFrame(columns=['Dataset', 'Metric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time_Table = pd.DataFrame(columns=['Dataset', 'Metric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fitness_Table = pd.DataFrame(columns=['Dataset', 'Metric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "Curve_Table = pd.DataFrame(columns=['Dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tables = [Accuracy_Table, Features_Table, Fitness_Table, Fitness_Table]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = './Filter/Convergence.csv'\n",
    "Curve_Table.to_csv(file_name)\n",
    "file_name = './Filter/Accuracy.csv'\n",
    "Tables[0].to_csv(file_name)\n",
    "file_name = './Filter/Features.csv'\n",
    "Tables[1].to_csv(file_name)\n",
    "file_name = './Filter/Time.csv'\n",
    "Tables[2].to_csv(file_name)\n",
    "file_name = './Filter/Fitness.csv'\n",
    "Tables[3].to_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfeat = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_score = []\n",
    "for col in range(X.shape[1]):\n",
    "    ans = pearsonr(X[:, col], y.reshape(-1))\n",
    "    pearson_score.append(abs(ans[0]))\n",
    "\n",
    "pearson_score = np.asarray(pearson_score)\n",
    "ps_std = (pearson_score - pearson_score.mean())/(pearson_score.std())\n",
    "\n",
    "n = np.size(X, 0)\n",
    "y_temp = y.reshape(n)        \n",
    "fs = ReliefF(n_neighbors=10, n_features_to_keep = nfeat)\n",
    "Xr = fs.fit_transform(X, y_temp)\n",
    "relief_score = fs.feature_scores\n",
    "rs_std = (relief_score - relief_score.mean())/(relief_score.std())\n",
    "\n",
    "mf = SelectKBest(f_classif, k=nfeat)\n",
    "Xf = mf.fit_transform(X, y.reshape(-1))\n",
    "f_score = mf.scores_\n",
    "fs_std = (f_score - f_score.mean())/(f_score.std())\n",
    "\n",
    "mf = SelectKBest(mutual_info_classif, k=nfeat)\n",
    "Xm = mf.fit_transform(X, y.reshape(-1))\n",
    "mi_score = mf.scores_\n",
    "ms_std = (mi_score - mi_score.mean())/(mi_score.std())\n",
    "\n",
    "matrix = np.asarray([ps_std, rs_std, fs_std, ms_std]).transpose()\n",
    "\n",
    "kmeans = MiniBatchKMeans(n_clusters = 3).fit(matrix)\n",
    "centres = kmeans.cluster_centers_\n",
    "scores = []\n",
    "for centre in centres:\n",
    "    mean_score = np.mean(centre)\n",
    "    scores.append(mean_score)\n",
    "\n",
    "max_score_index = 0\n",
    "for i in range(len(scores)):\n",
    "    if scores[i] > scores[max_score_index]:\n",
    "        max_score_index = i\n",
    "\n",
    "X_new = np.empty((X.shape[0], 0))\n",
    "\n",
    "labels = kmeans.labels_\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == max_score_index:\n",
    "        X_new = np.concatenate((X_new, X[:,i].reshape(-1, 1)), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(174,)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(174, 817)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
